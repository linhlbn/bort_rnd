{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "066c5c0f-6a37-43ca-b79b-f8d89953dc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pypdf\n",
    "# !pip install langchain\n",
    "# !pip install google-cloud-storage\n",
    "# !pip install openai\n",
    "# !pip install tiktoken\n",
    "# !pip install psycopg2\n",
    "# !pip install cloud-sql-python-connector\n",
    "# !pip install asyncio asyncpg\n",
    "# !pip install pgvector\n",
    "# !pip install PyPDF2\n",
    "# !pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e8e121b-b6d6-4d03-857b-814f54b1f4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sql_queries import embedding_related_created_queries\n",
    "\n",
    "from google.cloud.sql.connector import Connector\n",
    "from google.cloud import storage\n",
    "import asyncio\n",
    "import asyncpg\n",
    "import nest_asyncio\n",
    "import pickle\n",
    "\n",
    "from pgvector.asyncpg import register_vector\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "460b27c6-0e63-4173-863c-daa42126dbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) \n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa91b5a-b215-431e-9e40-56ae45807046",
   "metadata": {},
   "source": [
    "## UPDATE DATA info From Cloud Storage to CloudSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bee6d54-3a26-404a-acf4-bfce2bb404c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_blob():\n",
    "\n",
    "    storage_client = storage.Client.from_service_account_json(str(os.getenv('STORAGE_SERVICE_JSON')))\n",
    "    \n",
    "    bucket_name = os.getenv('STORAGE_NAME')\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    \n",
    "    blobs = bucket.list_blobs()\n",
    "\n",
    "loop_get_blob = asyncio.get_event_loop()\n",
    "\n",
    "# task_get_blob = loop_get_blob.create_task(update_storage_to_cloudsql())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cca0aba5-87eb-4d7d-beac-2c847b0b69ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_query_storage = \"\"\"\n",
    "    INSERT INTO document_storage (document_storage_dir, document_storage_filename, is_document_embedded) VALUES ($1, $2, $3);\n",
    "\"\"\"\n",
    "\n",
    "async def update_storage_to_cloudsql():\n",
    "    conn = await asyncpg.connect(\n",
    "        host=os.getenv('DB_HOST'),\n",
    "        database=os.getenv('DB_NAME'),\n",
    "        user=os.getenv('DB_USER'),\n",
    "        password=os.getenv('DB_PASS'),\n",
    "        port=os.getenv('DB_PORT')\n",
    "    )\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    blob = loop_get_blob.create_task(update_storage_to_cloudsql())\n",
    "    \n",
    "    for blob in blobs:\n",
    "        \n",
    "        dir_file_name = blob.name\n",
    "        downloaded_file_name = dir_file_name.split('/')[-1]\n",
    "        if downloaded_file_name.endswith('.pdf'):\n",
    "            existing_dir = await conn.fetchval('SELECT document_storage_dir FROM document_storage WHERE document_storage_dir = $1', dir_file_name)\n",
    "            if not existing_dir:\n",
    "                await conn.execute(insert_query_storage, dir_file_name, downloaded_file_name, blob.public_url, False)\n",
    "                print('Updated new document data')\n",
    "                count += 1\n",
    "    if count == 0:\n",
    "        print(\"Don't have new document updated from Cloud Storage!\")\n",
    "\n",
    "loop_update_storage_to_cloudsql = asyncio.get_event_loop()\n",
    "\n",
    "task_update_storage_to_cloudsql = loop_update_storage_to_cloudsql.create_task(update_storage_to_cloudsql())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9374f1-7591-4ce1-96b8-3ff9948d8fc6",
   "metadata": {},
   "source": [
    "## CREATE table if NOT EXISTS related to embedding process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e221025-45a0-4bde-a17d-90986cf75766",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def connect_create(queries):\n",
    "    conn = await asyncpg.connect(\n",
    "        host=os.getenv('DB_HOST'),\n",
    "        database=os.getenv('DB_NAME'),\n",
    "        user=os.getenv('DB_USER'),\n",
    "        password=os.getenv('DB_PASS'),\n",
    "        port=os.getenv('DB_PORT')\n",
    "    )\n",
    "    for query in queries:\n",
    "        await conn.execute(query)\n",
    "        print(\"Query created successfully.\")\n",
    "\n",
    "    await conn.close()\n",
    "\n",
    "loop_connect_create = asyncio.get_event_loop()\n",
    "\n",
    "task_connect_create = loop_connect_create.create_task(connect_create(embedding_related_created_queries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "594f33f6-2244-4f7f-a5fb-6333655f3821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback <TaskStepMethWrapper object at 0x115643580>()\n",
      "handle: <Handle <TaskStepMethWrapper object at 0x115643580>()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/thailinhpham/anaconda3/envs/t1/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "RuntimeError: Cannot enter into task <Task pending name='Task-5' coro=<update_storage_to_cloudsql() running at /var/folders/88/l6n2p6zj7k511lqxlc10jcvh0000gn/T/ipykernel_41833/2991273364.py:12>> while another task <Task pending name='Task-3' coro=<Kernel.dispatch_queue() running at /Users/thailinhpham/anaconda3/envs/t1/lib/python3.11/site-packages/ipykernel/kernelbase.py:516> cb=[IOLoop.add_future.<locals>.<lambda>() at /Users/thailinhpham/anaconda3/envs/t1/lib/python3.11/site-packages/tornado/ioloop.py:685]> is being executed.\n",
      "Exception in callback <TaskStepMethWrapper object at 0x115643d00>()\n",
      "handle: <Handle <TaskStepMethWrapper object at 0x115643d00>()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/thailinhpham/anaconda3/envs/t1/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "RuntimeError: Cannot enter into task <Task pending name='Task-6' coro=<connect_create() running at /var/folders/88/l6n2p6zj7k511lqxlc10jcvh0000gn/T/ipykernel_41833/3636135933.py:1>> while another task <Task pending name='Task-3' coro=<Kernel.dispatch_queue() running at /Users/thailinhpham/anaconda3/envs/t1/lib/python3.11/site-packages/ipykernel/kernelbase.py:516> cb=[IOLoop.add_future.<locals>.<lambda>() at /Users/thailinhpham/anaconda3/envs/t1/lib/python3.11/site-packages/tornado/ioloop.py:685]> is being executed.\n"
     ]
    }
   ],
   "source": [
    "async def task_for_counting():\n",
    "    conn = await asyncpg.connect(\n",
    "        host=os.getenv('DB_HOST'),\n",
    "        database=os.getenv('DB_NAME'),\n",
    "        user=os.getenv('DB_USER'),\n",
    "        password=os.getenv('DB_PASS'),\n",
    "        port=os.getenv('DB_PORT')\n",
    "    )\n",
    "    \n",
    "    # list_file_need_embedded\n",
    "    q_list_file_need_embedded = \"\"\"\n",
    "        SELECT document_storage_filename FROM document_storage WHERE is_document_embedded = false;\n",
    "    \"\"\"\n",
    "    \n",
    "    records = await conn.fetch(q_list_file_need_embedded)\n",
    "    list_file_need_embedded = [record['document_storage_filename'] for record in records]\n",
    "    \n",
    "    # number_of_embedded_file\n",
    "    q_number_of_embedded_file = \"\"\"\n",
    "    SELECT count(document_storage_filename) as number_of_embedded_file FROM document_storage WHERE is_document_embedded = true;\n",
    "    \"\"\"    \n",
    "    records = await conn.fetch(q_number_of_embedded_file)\n",
    "    number_of_embedded_file = [record['number_of_embedded_file'] for record in records]\n",
    "\n",
    "    await conn.close()\n",
    "    \n",
    "    return list_file_need_embedded, number_of_embedded_file[0]\n",
    "\n",
    "loop_task_for_counting = asyncio.get_event_loop()\n",
    "nest_asyncio.apply()\n",
    "list_file_need_embedded, number_of_embedded_file = loop_task_for_counting.run_until_complete(task_for_counting())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8a2786b-4fe2-402b-bc73-9777ae92714f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 files have been downloaded.\n"
     ]
    }
   ],
   "source": [
    "async def get_text_for_embbed():\n",
    "    count = 0\n",
    "    q_update_embedded = \"\"\"\n",
    "        UPDATE document_storage\n",
    "        SET is_document_embedded = true\n",
    "        WHERE document_storage_filename = ANY($1);\n",
    "    \"\"\"\n",
    "    loaders = []\n",
    "    \n",
    "    \n",
    "    storage_client = storage.Client.from_service_account_json(str(os.getenv('STORAGE_SERVICE_JSON')))\n",
    "    \n",
    "    bucket_name = os.getenv('STORAGE_NAME')\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    \n",
    "    blobs = bucket.list_blobs()\n",
    "    \n",
    "    \n",
    "    for blob in blobs:\n",
    "        dir_file_name = blob.name\n",
    "        downloaded_file_name = dir_file_name.split('/')[-1]\n",
    "        if downloaded_file_name in list_file_need_embedded:\n",
    "            if downloaded_file_name.endswith('.pdf'):\n",
    "                count += 1\n",
    "                blob.download_to_filename(downloaded_file_name)\n",
    "                # print(f\"The file {downloaded_file_name} has been downloaded.\")\n",
    "                loaders.append(PyPDFLoader(downloaded_file_name))\n",
    "                await conn.execute(q_update_embedded, (downloaded_file_name,))\n",
    "    \n",
    "    print(f\"{count} files have been downloaded.\")\n",
    "    docs = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    for loader in loaders:\n",
    "        docs.extend(loader.load())\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=[\".\", \"\\n\"],\n",
    "        chunk_size = 1536,\n",
    "        chunk_overlap = 0\n",
    "    )\n",
    "    \n",
    "    texts = text_splitter.split_documents(docs)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f49d18ae-5179-4bfe-b3c5-64dc2a72ff5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fbb9df9-d879-4a85-b2dc-b15bd1f869c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_query = \"\"\"\n",
    "    INSERT INTO document_embedding (chunk_file, privilege_id, tag, page_content, embedding) VALUES ($1, $2, $3, $4, $5);\n",
    "\"\"\"\n",
    "\n",
    "async def connect_execute(insert_query, chunk_file, privilege_id, tag,  splits):\n",
    "    conn = await asyncpg.connect(\n",
    "        host=os.getenv('DB_HOST'),\n",
    "        database=os.getenv('DB_NAME'),\n",
    "        user=os.getenv('DB_USER'),\n",
    "        password=os.getenv('DB_PASS'),\n",
    "        port=os.getenv('DB_PORT')\n",
    "    )\n",
    "\n",
    "    \n",
    "    await conn.execute(\"CREATE EXTENSION IF NOT EXISTS vector\")\n",
    "    await register_vector(conn)\n",
    "\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    doc_vector = embeddings.embed_documents([t.page_content for t in texts])\n",
    "\n",
    "    q_update_embedded = \"\"\"\n",
    "        UPDATE document_storage\n",
    "        SET is_document_embedded = true\n",
    "        WHERE document_storage_filename = ANY($1);\n",
    "    \"\"\"\n",
    "for file in list_file_need_embedded:\n",
    "    await conn.execute(q_update_embedded, (file,))\n",
    "\n",
    "    i = -1 \n",
    "    count_success = 0\n",
    "    for split in splits:\n",
    "        try:\n",
    "            i = i + 1\n",
    "            chunk_file +=1\n",
    "            await conn.execute(insert_query, chunk_file, privilege_id, tag, split.page_content, doc_vector[i])\n",
    "            count_success += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to add split: {e}\")\n",
    "\n",
    "    await conn.close()\n",
    "\n",
    "    percent = count_success / (i + 1) * 100\n",
    "    print(f'Embedded with {percent}% new files')\n",
    "\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "# number_of_embedded_file (chunk_file) will be continue count up as each embbed file has been vectorized\n",
    "\n",
    "tag = 'CV'\n",
    "privilege_id = 4\n",
    "\n",
    "embbed = loop.create_task(connect_execute(insert_query, number_of_embedded_file, privilege_id, tag, texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fa880e-c37f-44a0-8d8a-2f7ca2159329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4be23b5c-a8d7-4c7c-9b67-b90e050953ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'coroutine' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 121\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m document_manager\u001b[38;5;241m.\u001b[39mprocess_and_embed_documents()\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 121\u001b[0m     \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/t1/lib/python3.11/site-packages/nest_asyncio.py:31\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     29\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[0;32m~/anaconda3/envs/t1/lib/python3.11/site-packages/nest_asyncio.py:99\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/t1/lib/python3.11/asyncio/futures.py:203\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m~/anaconda3/envs/t1/lib/python3.11/asyncio/tasks.py:267\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    269\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "Cell \u001b[0;32mIn[29], line 118\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m document_manager \u001b[38;5;241m=\u001b[39m DocumentManager(storage_manager, db_manager, os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# # Process documents\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m document_manager\u001b[38;5;241m.\u001b[39mprocess_and_embed_documents()\n",
      "Cell \u001b[0;32mIn[29], line 84\u001b[0m, in \u001b[0;36mDocumentManager.process_and_embed_documents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter(separators\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m], chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1536\u001b[39m, chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Process the documents\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpdf_files\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfiles_to_embed\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblob\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbucket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'coroutine' object is not iterable"
     ]
    }
   ],
   "source": [
    "class StorageManager:\n",
    "    def __init__(self, service_account_json, bucket_name):\n",
    "        self.client = storage.Client.from_service_account_json(service_account_json)\n",
    "        self.bucket = self.client.bucket(bucket_name)\n",
    "\n",
    "    async def fetch_pdf_filenames(self):\n",
    "        blobs = [blob for blob in self.bucket.list_blobs() if blob.name.lower().endswith('.pdf')]\n",
    "        return [(blob.name, os.path.basename(blob.name)) for blob in blobs]\n",
    "\n",
    "class DatabaseManager:\n",
    "    def __init__(self, db_credentials):\n",
    "        self.db_credentials = db_credentials\n",
    "        self.pool = None\n",
    "\n",
    "    async def create_pool(self):\n",
    "        if not self.pool:\n",
    "            self.pool = await asyncpg.create_pool(**self.db_credentials)\n",
    "\n",
    "    async def close_pool(self):\n",
    "        if self.pool:\n",
    "            await self.pool.close()\n",
    "            self.pool = None\n",
    "\n",
    "    async def create_tables(self):\n",
    "        await self.create_pool()\n",
    "        async with self.pool.acquire() as conn:\n",
    "            for query in embedding_related_created_queries:\n",
    "                await conn.execute(query)\n",
    "\n",
    "    async def document_exists(self, filename):\n",
    "        async with self.pool.acquire() as conn:\n",
    "            return await conn.fetchval(\n",
    "                \"SELECT EXISTS(SELECT 1 FROM document_storage WHERE document_storage_filename = $1)\",\n",
    "                filename\n",
    "            )\n",
    "\n",
    "    async def insert_document_storage(self, dir_name, filename, is_embedded):\n",
    "        async with self.pool.acquire() as conn:\n",
    "            if not await self.document_exists(filename):\n",
    "                await conn.execute(\n",
    "                    \"INSERT INTO document_storage (document_storage_dir, document_storage_filename, is_document_embedded) \"\n",
    "                    \"VALUES ($1, $2, $3)\",\n",
    "                    dir_name, filename, is_embedded\n",
    "                )\n",
    "\n",
    "    async def fetch_documents_to_embed(self):\n",
    "        async with self.pool.acquire() as conn:\n",
    "            return await conn.fetch(\n",
    "                \"SELECT document_storage_filename FROM document_storage WHERE is_document_embedded = false\"\n",
    "            )\n",
    "\n",
    "    async def insert_document_embedding(self, chunk_file, privilege_id, tag, page_content, embedding):\n",
    "        async with self.pool.acquire() as conn:\n",
    "            await conn.execute(\n",
    "                \"INSERT INTO document_embedding (chunk_file, privilege_id, tag, page_content, embedding) \"\n",
    "                \"VALUES ($1, $2, $3, $4, $5)\",\n",
    "                chunk_file, privilege_id, tag, page_content, embedding\n",
    "            )\n",
    "\n",
    "    async def set_document_embedded(self, filename):\n",
    "        async with self.pool.acquire() as conn:\n",
    "            await conn.execute(\n",
    "                \"UPDATE document_storage SET is_document_embedded = true WHERE document_storage_filename = $1\",\n",
    "                filename\n",
    "            )\n",
    "\n",
    "\n",
    "class DocumentManager:\n",
    "    def __init__(self, storage_manager, database_manager, openai_api_key):\n",
    "        self.storage_manager = storage_manager\n",
    "        self.database_manager = database_manager\n",
    "        self.openai_api_key = openai_api_key\n",
    "\n",
    "    async def process_and_embed_documents(self):\n",
    "        pdf_files = self.storage_manager.fetch_pdf_filenames()\n",
    "        await self.database_manager.create_pool()  # Make sure the pool is created\n",
    "        files_to_embed = [record['document_storage_filename'] for record in\n",
    "                          await self.database_manager.fetch_documents_to_embed()]\n",
    "\n",
    "        embeddings = OpenAIEmbeddings(api_key=self.openai_api_key)\n",
    "        text_splitter = RecursiveCharacterTextSplitter(separators=[\".\", \"\\n\"], chunk_size=1536, chunk_overlap=0)\n",
    "\n",
    "        # Process the documents\n",
    "        for file_path, file_name in pdf_files:\n",
    "            if file_name in files_to_embed:\n",
    "                blob = self.storage_manager.bucket.blob(file_path)\n",
    "                local_file_path = f\"/tmp/{file_name}\"\n",
    "                blob.download_to_filename(local_file_path)\n",
    "\n",
    "                # Load the document content\n",
    "                loader = PyPDFLoader(local_file_path)\n",
    "                document = loader.load()\n",
    "\n",
    "                # Split and embed the text\n",
    "                splits = text_splitter.split_documents([document])\n",
    "                doc_vector = embeddings.embed_documents([split.page_content for split in splits])\n",
    "\n",
    "                for i, split in enumerate(splits):\n",
    "                    # Insert embedding into database\n",
    "                    await self.database_manager.insert_document_embedding(2, 4, 'CV', split.page_content,\n",
    "                                                                         doc_vector[i])\n",
    "\n",
    "                # Update the document_storage as embedded\n",
    "                await self.database_manager.set_document_embedded(file_name)\n",
    "\n",
    "async def main():\n",
    "    db_manager = DatabaseManager({\n",
    "        'host': os.getenv('DB_HOST'),\n",
    "        'database': os.getenv('DB_NAME'),\n",
    "        'user': os.getenv('DB_USER'),\n",
    "        'password': os.getenv('DB_PASS'),\n",
    "        'port': os.getenv('DB_PORT')\n",
    "    })\n",
    "    # # Initialize the pool and create tables\n",
    "    storage_manager = StorageManager(os.getenv('STORAGE_SERVICE_JSON'), os.getenv('STORAGE_NAME'))\n",
    "    document_manager = DocumentManager(storage_manager, db_manager, os.getenv('OPENAI_API_KEY'))\n",
    "    # # Process documents\n",
    "    await document_manager.process_and_embed_documents()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ec611e-797b-4613-b584-7ff2e8e68553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b392bc3b-1a70-4730-b6a6-58222d8cc1ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "TooManyConnectionsError",
     "evalue": "sorry, too many clients already :: proc.c:360",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTooManyConnectionsError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 132\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m document_manager\u001b[38;5;241m.\u001b[39mprocess_and_embed_documents()\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 132\u001b[0m     \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/t1/lib/python3.11/site-packages/nest_asyncio.py:31\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     29\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[0;32m~/anaconda3/envs/t1/lib/python3.11/site-packages/nest_asyncio.py:99\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/t1/lib/python3.11/asyncio/futures.py:203\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m~/anaconda3/envs/t1/lib/python3.11/asyncio/tasks.py:269\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    267\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 269\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_must_cancel:\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[42], line 129\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m document_manager \u001b[38;5;241m=\u001b[39m DocumentManager(storage_manager, db_manager, os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# # Process documents\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m document_manager\u001b[38;5;241m.\u001b[39mprocess_and_embed_documents()\n",
      "Cell \u001b[0;32mIn[42], line 74\u001b[0m, in \u001b[0;36mDocumentManager.process_and_embed_documents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_and_embed_documents\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     73\u001b[0m     pdf_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_manager\u001b[38;5;241m.\u001b[39mfetch_pdf_filenames()\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatabase_manager\u001b[38;5;241m.\u001b[39mcreate_pool()  \u001b[38;5;66;03m# Ensure the connection pool is created\u001b[39;00m\n\u001b[1;32m     75\u001b[0m     files_to_embed \u001b[38;5;241m=\u001b[39m [filename \u001b[38;5;28;01mfor\u001b[39;00m _, filename \u001b[38;5;129;01min\u001b[39;00m pdf_files]\n\u001b[1;32m     76\u001b[0m     files_to_embed_records \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatabase_manager\u001b[38;5;241m.\u001b[39mfetch_documents_to_embed()\n",
      "Cell \u001b[0;32mIn[42], line 16\u001b[0m, in \u001b[0;36mDatabaseManager.create_pool\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_pool\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool:\n\u001b[0;32m---> 16\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncpg\u001b[38;5;241m.\u001b[39mcreate_pool(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdb_credentials)\n",
      "File \u001b[0;32m~/anaconda3/envs/t1/lib/python3.11/site-packages/asyncpg/pool.py:403\u001b[0m, in \u001b[0;36mPool._async__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize()\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/t1/lib/python3.11/site-packages/asyncpg/pool.py:440\u001b[0m, in \u001b[0;36mPool._initialize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    438\u001b[0m     connect_tasks\u001b[38;5;241m.\u001b[39mappend(ch\u001b[38;5;241m.\u001b[39mconnect())\n\u001b[0;32m--> 440\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mconnect_tasks)\n",
      "File \u001b[0;32m~/anaconda3/envs/t1/lib/python3.11/asyncio/tasks.py:339\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 339\u001b[0m         \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    341\u001b[0m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n",
      "File \u001b[0;32m~/anaconda3/envs/t1/lib/python3.11/asyncio/tasks.py:269\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    267\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 269\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_must_cancel:\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/t1/lib/python3.11/site-packages/asyncpg/pool.py:128\u001b[0m, in \u001b[0;36mPoolConnectionHolder.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_con \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mInternalClientError(\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPoolConnectionHolder.connect() called while another \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconnection already exists\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_con \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39m_get_new_connection()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39m_generation\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cancel_inactive_callback()\n",
      "File \u001b[0;32m~/anaconda3/envs/t1/lib/python3.11/site-packages/asyncpg/pool.py:502\u001b[0m, in \u001b[0;36mPool._get_new_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_new_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 502\u001b[0m     con \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m connection\u001b[38;5;241m.\u001b[39mconnect(\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_args,\n\u001b[1;32m    504\u001b[0m         loop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop,\n\u001b[1;32m    505\u001b[0m         connection_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection_class,\n\u001b[1;32m    506\u001b[0m         record_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_record_class,\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_kwargs,\n\u001b[1;32m    508\u001b[0m     )\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/t1/lib/python3.11/site-packages/asyncpg/connection.py:2329\u001b[0m, in \u001b[0;36mconnect\u001b[0;34m(dsn, host, port, user, password, passfile, database, loop, timeout, statement_cache_size, max_cached_statement_lifetime, max_cacheable_statement_size, command_timeout, ssl, direct_tls, connection_class, record_class, server_settings, target_session_attrs)\u001b[0m\n\u001b[1;32m   2326\u001b[0m     loop \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mget_event_loop()\n\u001b[1;32m   2328\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m compat\u001b[38;5;241m.\u001b[39mtimeout(timeout):\n\u001b[0;32m-> 2329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m connect_utils\u001b[38;5;241m.\u001b[39m_connect(\n\u001b[1;32m   2330\u001b[0m         loop\u001b[38;5;241m=\u001b[39mloop,\n\u001b[1;32m   2331\u001b[0m         connection_class\u001b[38;5;241m=\u001b[39mconnection_class,\n\u001b[1;32m   2332\u001b[0m         record_class\u001b[38;5;241m=\u001b[39mrecord_class,\n\u001b[1;32m   2333\u001b[0m         dsn\u001b[38;5;241m=\u001b[39mdsn,\n\u001b[1;32m   2334\u001b[0m         host\u001b[38;5;241m=\u001b[39mhost,\n\u001b[1;32m   2335\u001b[0m         port\u001b[38;5;241m=\u001b[39mport,\n\u001b[1;32m   2336\u001b[0m         user\u001b[38;5;241m=\u001b[39muser,\n\u001b[1;32m   2337\u001b[0m         password\u001b[38;5;241m=\u001b[39mpassword,\n\u001b[1;32m   2338\u001b[0m         passfile\u001b[38;5;241m=\u001b[39mpassfile,\n\u001b[1;32m   2339\u001b[0m         ssl\u001b[38;5;241m=\u001b[39mssl,\n\u001b[1;32m   2340\u001b[0m         direct_tls\u001b[38;5;241m=\u001b[39mdirect_tls,\n\u001b[1;32m   2341\u001b[0m         database\u001b[38;5;241m=\u001b[39mdatabase,\n\u001b[1;32m   2342\u001b[0m         server_settings\u001b[38;5;241m=\u001b[39mserver_settings,\n\u001b[1;32m   2343\u001b[0m         command_timeout\u001b[38;5;241m=\u001b[39mcommand_timeout,\n\u001b[1;32m   2344\u001b[0m         statement_cache_size\u001b[38;5;241m=\u001b[39mstatement_cache_size,\n\u001b[1;32m   2345\u001b[0m         max_cached_statement_lifetime\u001b[38;5;241m=\u001b[39mmax_cached_statement_lifetime,\n\u001b[1;32m   2346\u001b[0m         max_cacheable_statement_size\u001b[38;5;241m=\u001b[39mmax_cacheable_statement_size,\n\u001b[1;32m   2347\u001b[0m         target_session_attrs\u001b[38;5;241m=\u001b[39mtarget_session_attrs\n\u001b[1;32m   2348\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/t1/lib/python3.11/site-packages/asyncpg/connect_utils.py:991\u001b[0m, in \u001b[0;36m_connect\u001b[0;34m(loop, connection_class, record_class, **kwargs)\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m addr \u001b[38;5;129;01min\u001b[39;00m addrs:\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 991\u001b[0m         conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m _connect_addr(\n\u001b[1;32m    992\u001b[0m             addr\u001b[38;5;241m=\u001b[39maddr,\n\u001b[1;32m    993\u001b[0m             loop\u001b[38;5;241m=\u001b[39mloop,\n\u001b[1;32m    994\u001b[0m             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    995\u001b[0m             config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m    996\u001b[0m             connection_class\u001b[38;5;241m=\u001b[39mconnection_class,\n\u001b[1;32m    997\u001b[0m             record_class\u001b[38;5;241m=\u001b[39mrecord_class,\n\u001b[1;32m    998\u001b[0m         )\n\u001b[1;32m    999\u001b[0m         candidates\u001b[38;5;241m.\u001b[39mappend(conn)\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _can_use_connection(conn, target_attr):\n",
      "File \u001b[0;32m~/anaconda3/envs/t1/lib/python3.11/site-packages/asyncpg/connect_utils.py:828\u001b[0m, in \u001b[0;36m_connect_addr\u001b[0;34m(addr, loop, params, config, connection_class, record_class)\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;66;03m# first attempt\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 828\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m __connect_addr(params, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _RetryConnectSignal:\n\u001b[1;32m    830\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/t1/lib/python3.11/site-packages/asyncpg/connect_utils.py:876\u001b[0m, in \u001b[0;36m__connect_addr\u001b[0;34m(params, retry, addr, loop, config, connection_class, record_class, params_input)\u001b[0m\n\u001b[1;32m    873\u001b[0m tr, pr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m connector\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 876\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m connected\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[1;32m    878\u001b[0m     exceptions\u001b[38;5;241m.\u001b[39mInvalidAuthorizationSpecificationError,\n\u001b[1;32m    879\u001b[0m     exceptions\u001b[38;5;241m.\u001b[39mConnectionDoesNotExistError,  \u001b[38;5;66;03m# seen on Windows\u001b[39;00m\n\u001b[1;32m    880\u001b[0m ):\n\u001b[1;32m    881\u001b[0m     tr\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/t1/lib/python3.11/asyncio/futures.py:287\u001b[0m, in \u001b[0;36mFuture.__await__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncio_future_blocking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mawait wasn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt used with future\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/t1/lib/python3.11/asyncio/tasks.py:339\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 339\u001b[0m         \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    341\u001b[0m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n",
      "File \u001b[0;32m~/anaconda3/envs/t1/lib/python3.11/asyncio/futures.py:203\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "\u001b[0;31mTooManyConnectionsError\u001b[0m: sorry, too many clients already :: proc.c:360"
     ]
    }
   ],
   "source": [
    "class StorageManager:\n",
    "    def __init__(self, service_account_json, bucket_name):\n",
    "        self.client = storage.Client.from_service_account_json(service_account_json)\n",
    "        self.bucket = self.client.bucket(bucket_name)\n",
    "\n",
    "    def fetch_pdf_filenames(self):\n",
    "        return [(blob.name, os.path.basename(blob.name)) for blob in self.bucket.list_blobs() if blob.name.lower().endswith('.pdf')]\n",
    "\n",
    "class DatabaseManager:\n",
    "    def __init__(self, db_credentials):\n",
    "        self.db_credentials = db_credentials\n",
    "        self.pool = None\n",
    "\n",
    "    async def create_pool(self):\n",
    "        if not self.pool:\n",
    "            self.pool = await asyncpg.create_pool(**self.db_credentials)\n",
    "\n",
    "    async def close_pool(self):\n",
    "        if self.pool:\n",
    "            await self.pool.close()\n",
    "            self.pool = None\n",
    "\n",
    "    async def create_tables(self):\n",
    "        await self.create_pool()\n",
    "        async with self.pool.acquire() as conn:\n",
    "            for query in embedding_related_created_queries:\n",
    "                await conn.execute(query)\n",
    "\n",
    "    async def document_exists(self, filename):\n",
    "        async with self.pool.acquire() as conn:\n",
    "            return await conn.fetchval(\n",
    "                \"SELECT EXISTS(SELECT 1 FROM document_storage WHERE document_storage_filename = $1)\",\n",
    "                filename\n",
    "            )\n",
    "\n",
    "    async def insert_document_storage(self, dir_name, filename, is_embedded):\n",
    "        async with self.pool.acquire() as conn:\n",
    "            if not await self.document_exists(filename):\n",
    "                await conn.execute(\n",
    "                    \"INSERT INTO document_storage (document_storage_dir, document_storage_filename, is_document_embedded) \"\n",
    "                    \"VALUES ($1, $2, $3)\",\n",
    "                    dir_name, filename, is_embedded\n",
    "                )\n",
    "\n",
    "    async def fetch_documents_to_embed(self):\n",
    "        async with self.pool.acquire() as conn:\n",
    "            return await conn.fetch(\n",
    "                \"SELECT document_storage_filename FROM document_storage WHERE is_document_embedded = false\"\n",
    "            )\n",
    "\n",
    "    async def insert_document_embedding(self, chunk_file, privilege_id, tag, page_content, embedding):\n",
    "        async with self.pool.acquire() as conn:\n",
    "            await conn.execute(\n",
    "                \"INSERT INTO document_embedding (chunk_file, privilege_id, tag, page_content, embedding) \"\n",
    "                \"VALUES ($1, $2, $3, $4, $5)\",\n",
    "                chunk_file, privilege_id, tag, page_content, embedding\n",
    "            )\n",
    "\n",
    "    async def set_document_embedded(self, filename):\n",
    "        async with self.pool.acquire() as conn:\n",
    "            await conn.execute(\n",
    "                \"UPDATE document_storage SET is_document_embedded = true WHERE document_storage_filename = $1\",\n",
    "                filename\n",
    "            )\n",
    "\n",
    "class DocumentManager:\n",
    "    def __init__(self, storage_manager, database_manager, openai_api_key):\n",
    "        self.storage_manager = storage_manager\n",
    "        self.database_manager = database_manager\n",
    "        self.openai_api_key = openai_api_key\n",
    "\n",
    "    async def process_and_embed_documents(self):\n",
    "        pdf_files = self.storage_manager.fetch_pdf_filenames()\n",
    "        await self.database_manager.create_pool()  # Ensure the connection pool is created\n",
    "        files_to_embed = [filename for _, filename in pdf_files]\n",
    "        files_to_embed_records = await self.database_manager.fetch_documents_to_embed()\n",
    "\n",
    "        # Filter the files based on whether they need to be embedded.\n",
    "        files_to_embed = {record['document_storage_filename'] for record in files_to_embed_records}.intersection(files_to_embed)\n",
    "\n",
    "        embeddings = OpenAIEmbeddings(api_key=self.openai_api_key)\n",
    "        text_splitter = RecursiveCharacterTextSplitter(separators=[\".\", \"\\n\"], chunk_size=1536, chunk_overlap=0)\n",
    "\n",
    "        # Process the documents\n",
    "        for file_path, file_name in pdf_files:\n",
    "            if file_name in files_to_embed:\n",
    "                # print(f'{file_name} file needs to be embedd')\n",
    "                blob = self.storage_manager.bucket.blob(file_path)\n",
    "                print(file_path)\n",
    "                # local_file_path = f\"{}\"\n",
    "                print(local_file_path)\n",
    "                blob.download_to_filename(local_file_path)\n",
    "\n",
    "                # Load the document content\n",
    "                loader = PyPDFLoader(local_file_path)\n",
    "                document = loader.load()\n",
    "\n",
    "                # Split and embed the text\n",
    "                splits = text_splitter.split_documents(document)\n",
    "                doc_vectors = embeddings.embed_documents([t.page_content for t in texts]) \n",
    "\n",
    "                i = -1\n",
    "                \n",
    "                for split in splits:\n",
    "                    # Insert embedding into the database\n",
    "                    print(doc_vectors)\n",
    "                    i += 1\n",
    "                    await self.database_manager.insert_document_embedding(i, 4, 'CV', split.page_content, doc_vectors[i])  # Adjust the i+1 based on your chunk_file id strategy\n",
    "                    \n",
    "                # Update the document_storage as embedded\n",
    "                await self.database_manager.set_document_embedded(file_name)\n",
    "\n",
    "        # After processing, close the pool\n",
    "        await self.database_manager.close_pool()\n",
    "        print('Done')\n",
    "\n",
    "async def main():\n",
    "    db_manager = DatabaseManager({\n",
    "        'host': os.getenv('DB_HOST'),\n",
    "        'database': os.getenv('DB_NAME'),\n",
    "        'user': os.getenv('DB_USER'),\n",
    "        'password': os.getenv('DB_PASS'),\n",
    "        'port': os.getenv('DB_PORT')\n",
    "    })\n",
    "    # # Initialize the pool and create tables\n",
    "    storage_manager = StorageManager(os.getenv('STORAGE_SERVICE_JSON'), os.getenv('STORAGE_NAME'))\n",
    "    document_manager = DocumentManager(storage_manager, db_manager, os.getenv('OPENAI_API_KEY'))\n",
    "    # # Process documents\n",
    "    await document_manager.process_and_embed_documents()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300491dd-90b5-4124-8240-eeea79c3981a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
